{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyyupoglu/02456-deep-learning-with-PyTorch/blob/master/working_back_and_forth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ziq3yDmSWFiX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cBuyGcL4WL0K",
        "colab_type": "code",
        "outputId": "85742e9f-d410-4b40-c9a0-446b5294f687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YfPiWOy2WL06",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.onnx\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PgPlH_vEWNA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "\n",
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        self.train = self.tokenize(os.path.join(path, 'ptb.train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'ptb.valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'ptb.test.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "\n",
        "            tokens = 0\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                tokens += len(words)\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            ids = torch.LongTensor(tokens)\n",
        "            token = 0\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    ids[token] = self.dictionary.word2idx[word]\n",
        "                    token += 1\n",
        "\n",
        "        return ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GRK7gjdIYQs8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "batch_size = 20\n",
        "corpus = Corpus('./gdrive/My Drive/nlp/data/raw/penn-treebank')\n",
        "\n",
        "# Starting from sequential data, batchify arranges the dataset into columns.\n",
        "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
        "# ┌ a g m s ┐\n",
        "# │ b h n t │\n",
        "# │ c i o u │\n",
        "# │ d j p v │\n",
        "# │ e k q w │\n",
        "# └ f l r x ┘.\n",
        "# These columns are treated as independent by the model, which means that the\n",
        "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
        "# batch processing.\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(corpus.train, batch_size)\n",
        "val_data = batchify(corpus.valid, eval_batch_size)\n",
        "test_data = batchify(corpus.test, eval_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7FblJYsLY-hL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class RNNModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5, tie_weights=False):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.rnn = RNN_mehmet(ninp, nhid).to(device)\n",
        "#         if rnn_type in ['LSTM', 'GRU']:\n",
        "#             self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
        "#         else:\n",
        "#             try:\n",
        "#                 nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
        "#             except KeyError:\n",
        "#                 raise ValueError( \"\"\"An invalid option for `--model` was supplied,\n",
        "#                                  options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
        "#             self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "\n",
        "        # Optionally tie weights as in:\n",
        "        # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\n",
        "        # https://arxiv.org/abs/1608.05859\n",
        "        # and\n",
        "        # \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)\n",
        "        # https://arxiv.org/abs/1611.01462\n",
        "        if tie_weights:\n",
        "            if nhid != ninp:\n",
        "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
        "            self.decoder.weight = self.encoder.weight\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        emb = self.drop(self.encoder(input))\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop(output)\n",
        "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))  \n",
        "        ext_output = decoded.view(output.size(0), output.size(1), decoded.size(1))\n",
        "        return ext_output, hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters())\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
        "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\n",
        "        else:\n",
        "            return weight.new_zeros(self.nlayers, bsz, self.nhid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CIa4B38jZUIN",
        "colab_type": "code",
        "outputId": "69554b1f-55f9-484b-bae3-06660f2eea90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "emsize = 200\n",
        "nhid = 200\n",
        "nlayers = 1\n",
        "dropout = 0.5\n",
        "tied = False\n",
        "\n",
        "ntokens = len(corpus.dictionary)\n",
        "model = RNNModel('LSTM', ntokens, emsize, nhid, nlayers, dropout, tied).to(device)\n",
        "print(model)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNNModel(\n",
            "  (drop): Dropout(p=0.5)\n",
            "  (encoder): Embedding(10000, 200)\n",
            "  (rnn): RNN_mehmet()\n",
            "  (decoder): Linear(in_features=200, out_features=10000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jycx92tZZW4D",
        "colab_type": "code",
        "outputId": "56d855b3-6ce1-496d-cea6-182f372f4c66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        }
      },
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Training code\n",
        "###############################################################################\n",
        "\n",
        "bptt = 35\n",
        "clip = 0.25\n",
        "log_interval = 100\n",
        "epochs = 25\n",
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "\n",
        "# get_batch subdivides the source data into chunks of length bptt.\n",
        "# If source is equal to the example output of the batchify function, with\n",
        "# a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
        "# ┌ a g m s ┐ ┌ b h n t ┐\n",
        "# └ b h n t ┘ └ c i o u ┘\n",
        "# Note that despite the name of the function, the subdivison of data is not\n",
        "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
        "# by the batchify function. The chunks are along dimension 0, corresponding\n",
        "# to the seq_len dimension in the LSTM.\n",
        "\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].view(-1)\n",
        "    return data, target\n",
        "\n",
        "\n",
        "def evaluate(data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    hidden = model.init_hidden(eval_batch_size)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            output, hidden = model(data, hidden)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "            hidden = repackage_hidden(hidden)\n",
        "    return total_loss / (len(data_source) - 1)\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Turn on training mode which enables dropout.\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    ntokens = len(corpus.dictionary)\n",
        "#     print('N-tokens', ntokens)\n",
        "    hidden, _ = model.init_hidden(batch_size)\n",
        "    for batch, i in enumerate(range(0, 2 - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "#         print(data.shape)\n",
        "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
        "        hidden = repackage_hidden(hidden)\n",
        "        model.zero_grad()\n",
        "        output, hidden = model(data, hidden)\n",
        "        print('output ', output.size())\n",
        "        print('output view', output.view(-1, ntokens).size())\n",
        "        print('targets', targets.size())\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "        print('loss', loss)\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        for p in model.parameters():\n",
        "           \n",
        "            p.data.add_(-lr, p.grad.data)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                    'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                epoch, batch, len(train_data) // bptt, lr,\n",
        "                elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "# Loop over epochs.\n",
        "lr = 20\n",
        "best_val_loss = None\n",
        "save_file = 'best_model'\n",
        "\n",
        "# At any point you can hit Ctrl + C to break out of training early.\n",
        "try:\n",
        "    for epoch in range(1, epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        train()\n",
        "        val_loss = evaluate(val_data)\n",
        "        print('-' * 89)\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                           val_loss, math.exp(val_loss)))\n",
        "        print('-' * 89)\n",
        "        # Save the model if the validation loss is the best we've seen so far.\n",
        "        if not best_val_loss or val_loss < best_val_loss:\n",
        "            with open(save_file, 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_val_loss = val_loss\n",
        "        else:\n",
        "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
        "            lr /= 4.0\n",
        "except KeyboardInterrupt:\n",
        "    print('-' * 89)\n",
        "    print('Exiting from training early')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-d9d9c411e27a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m89\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-110-d9d9c411e27a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepackage_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output view'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-108-70be710564fe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mext_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mext_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.cuda.FloatTensor but found type torch.FloatTensor for argument #4 'mat1'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6sFFwhPcTxAN",
        "colab_type": "code",
        "outputId": "c9eb0d52-c1bc-4afd-d002-13209fdebc82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# coding: utf-8\n",
        "\n",
        "# In[1]:\n",
        "\n",
        "import itertools\n",
        "import operator\n",
        "from datetime import datetime\n",
        "import sys\n",
        "from torch import FloatTensor\n",
        "from torch.autograd import Variable\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "vocabulary_size = 8000\n",
        "\n",
        "\n",
        "class RNN_mehmet(nn.Module):\n",
        "    def __init__(self, word_dim, hidden_dim = 100, activation = 'sigmoid'):\n",
        "        super(RNN_mehmet, self).__init__()\n",
        "\n",
        "        self.word_dim = word_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.weights_hh = self.init_weights((hidden_dim, hidden_dim))\n",
        "        self.weights_xh = self.init_weights((hidden_dim, word_dim))\n",
        "        self.weights_o = self.init_weights((word_dim, hidden_dim))\n",
        "        self.activation = getattr(torch, activation)\n",
        "\n",
        "\n",
        "  \n",
        "    def init_weights(self, dim):\n",
        "        return nn.Parameter(torch.FloatTensor(dim[0], dim[1]).uniform_(-np.sqrt(1./dim[0]), np.sqrt(1./dim[1])), requires_grad=True)\n",
        "    def softmax(self, x):\n",
        "        xt = torch.exp(x - torch.max(x))\n",
        "        return xt / xt.sum()\n",
        "      \n",
        "    \n",
        "    def init_hidden(self, batch_size, dim):\n",
        "        layer = torch.zeros((1, batch_size, self.hidden_dim),  requires_grad = True)\n",
        "        if dim > 1:\n",
        "           layer = (layer.clone(), layer.clone())\n",
        "        return layer\n",
        "      \n",
        "    def step(self, lr):\n",
        "        for p in self.parameters():\n",
        "            p.data.add_(-lr, p.grad.data)\n",
        "      \n",
        "    def forward_step(self, xt, hidden_t_1):\n",
        "        # clone weights\n",
        "        weights_xh = self.weights_xh.clone()\n",
        "        weights_hh = self.weights_hh.clone()\n",
        "        weights_o = self.weights_o.clone()\n",
        "        \n",
        "        # calculate left and right terms\n",
        "        left_term = F.linear(xt, weights_xh)\n",
        "        right_term = F.linear(hidden_t_1, weights_hh)\n",
        "        \n",
        "        # sum terms\n",
        "        sum_ = left_term + right_term\n",
        "        \n",
        "        # activation for hidden state\n",
        "        hidden_t = self.activation(sum_)\n",
        "        \n",
        "        # calculate output\n",
        "        output = F.linear(hidden_t, weights_o)\n",
        "        return output, hidden_t\n",
        "\n",
        "    def forward_propagation(self, x, hidden_t_1):\n",
        "        # Get sequence length (bptt), batch_size from the input\n",
        "        bptt, batch_size, _ = x.size()\n",
        "        output = torch.zeros((bptt, batch_size, self.word_dim))\n",
        "        \n",
        "        # loop over sequence\n",
        "        for t in torch.arange(bptt): \n",
        "            xt = x[t,:,:]\n",
        "         \n",
        "            output[t], hidden_t_1 = self.forward_step(xt, hidden_t_1)\n",
        "        return [output, hidden_t_1]\n",
        "      \n",
        "    def __call__(self, x, hidden_t_1):\n",
        "        return self.forward_propagation(x, hidden_t_1)\n",
        "\n",
        "fake_net = RNN_mehmet(emsize, hidden_dim = 130)\n",
        "\n",
        "#forward_prop\n",
        "# test forward pass\n",
        "x = np.random.normal(0, 1, (bptt, batch_size, emsize)).astype('float32')\n",
        "x = torch.Tensor(torch.from_numpy(x))\n",
        "\n",
        "hidden = fake_net.init_hidden(batch_size, 1)\n",
        "\n",
        "y = np.random.normal(0, 1, (bptt * batch_size, emsize)).astype('float32')\n",
        "y = torch.Tensor(torch.from_numpy(y)).long()\n",
        "\n",
        "\n",
        "print(result[0].size())\n",
        "\n",
        "\n",
        "\n",
        "#example backward and 10 steps\n",
        "\n",
        "for i in range(10):\n",
        "    fake_net.zero_grad()\n",
        "    result = fake_net.forward_propagation(x, hidden)\n",
        "    output =  result[0].view(-1, emsize)\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "    loss = loss_fn(output, y.float())\n",
        "    print(loss)\n",
        "    loss.backward()\n",
        "    fake_net.step(0.01)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([35, 20, 200])\n",
            "tensor(0.8565, grad_fn=<MseLossBackward>)\n",
            "tensor(0.8537, grad_fn=<MseLossBackward>)\n",
            "tensor(0.8509, grad_fn=<MseLossBackward>)\n",
            "tensor(0.8481, grad_fn=<MseLossBackward>)\n",
            "tensor(0.8454, grad_fn=<MseLossBackward>)\n",
            "tensor(0.8426, grad_fn=<MseLossBackward>)\n",
            "tensor(0.8399, grad_fn=<MseLossBackward>)\n",
            "tensor(0.8372, grad_fn=<MseLossBackward>)\n",
            "tensor(0.8346, grad_fn=<MseLossBackward>)\n",
            "tensor(0.8319, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wh7SoG93ZtLe",
        "colab_type": "code",
        "outputId": "3972b526-26f6-4599-fb21-a046423feb54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "cell_type": "code",
      "source": [
        "# New RNN Layer\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RNNCustom(nn.Module):\n",
        "  \n",
        "  def __init__(self, ninput, nhid, activation = 'sigmoid'):\n",
        "      self.ninput = ninput\n",
        "      self.nhid = nhid\n",
        "      self.weights_hh = self.init_weights((nhid, nhid))\n",
        "      self.weights_xh = self.init_weights((nhid, ninput))\n",
        "      self.activation = getattr(F, activation)\n",
        "      self._modules = {}\n",
        "    \n",
        "  def init_weights(self, dimensions):\n",
        "      return torch.zeros(dimensions, requires_grad = True).to(device)\n",
        "      \n",
        "  def init_hidden(self):\n",
        "      layer = torch.zeros((1, batch_size, self.nhid),  requires_grad = True).to(device)\n",
        "      return (layer, layer)\n",
        "    \n",
        "  def step(self, xt, ht_1):\n",
        "      # calculate product of weights and inputs\n",
        "      print('xt', xt.size())\n",
        "      print('weights', self.weights_xh.size())\n",
        "      xt = F.linear(xt, self.weights_xh)\n",
        "      ht_1 = F.linear(ht_1, self.weights_hh)\n",
        "      \n",
        "      # return activation of concatenated products\n",
        "      return self.activation(xt + ht_1), ht_1\n",
        "      \n",
        "    \n",
        "  def forward(self, x, hidden):\n",
        "      # Get sequence length (bptt), batch_size from the input\n",
        "      bptt, batch_size, _ = x.size()\n",
        "      \n",
        "      # intialize output\n",
        "      output = torch.zeros((bptt, batch_size, self.ninput), requires_grad = True).to(device)\n",
        "      \n",
        "      # hidden layers\n",
        "      ht_1, ht = hidden\n",
        "      \n",
        "      # loop over sequence\n",
        "      for i in range(bptt):\n",
        "        \n",
        "        # slice input \n",
        "        xt = x[i,:,:]\n",
        "       \n",
        "        # store step output\n",
        "        output[i,:,:], ht = self.step(xt, ht_1)\n",
        "        \n",
        "        # update hidden states\n",
        "        ht_1 = ht\n",
        "      \n",
        "      # return output, (hidden, hidden)\n",
        "      return output, (ht_1, ht)\n",
        "    \n",
        "  def __call__(self, x, hidden):\n",
        "      return self.forward(x, hidden)\n",
        "    \n",
        "\n",
        "# test forward pass\n",
        "x = np.random.normal(0, 1, (bptt, batch_size, emsize)).astype('float32')\n",
        "\n",
        "# double hidden only necesary for LSTM\n",
        "hidden_layer = np.zeros((1, batch_size, nhid)).astype('float32')\n",
        "hidden_layer_tensor = torch.Tensor(torch.from_numpy(hidden_layer)).to(device)\n",
        "hidden = (hidden_layer_tensor, hidden_layer_tensor)\n",
        "\n",
        "\n",
        "# output is still very different\n",
        "rnn_pt = nn.RNN(emsize, nhid)\n",
        "output, h = rnn_pt(torch.Tensor(torch.from_numpy(x)))\n",
        "# print('RNN TORCH', output)\n",
        "\n",
        "rnn_cust = RNNCustom(ninput = emsize, nhid = nhid)\n",
        "output, h = rnn_cust(torch.Tensor(torch.from_numpy(x)).to(device), hidden)\n",
        "# print('RNN cust', output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xt torch.Size([20, 200])\n",
            "weights torch.Size([300, 200])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-c5f3e1a020a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mrnn_cust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNNCustom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mninput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_cust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;31m# print('RNN cust', output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-c5f3e1a020a4>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-c5f3e1a020a4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# store step output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# update hidden states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (200) must match the existing size (300) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Zw-6SgZxhQ3G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dimensionality Analysis\n",
        "\n",
        "I used the implementation above to go through all the different dimensions. Maybe this helps you understanding how to implement the RNN / LSTM layer.\n",
        "\n",
        "I also tried looking at: https://www.quora.com/In-LSTM-how-do-you-figure-out-what-size-the-weights-are-supposed-to-be\n",
        "\n",
        "Also, look here: https://github.com/pytorch/pytorch/blob/v0.3.0/torch/nn/_functions/rnn.py\n",
        "\n",
        "### Some variables\n",
        "\n",
        "* bptt = \"backpropagation through time\", but here used as the sequence length that we feed at once. It's given in dim=0 aling the 'seq_len' dimension in the LSTM given in the original code. Given above to be 35.\n",
        "* bsz = \"batch size\", number of sequences looked at at once, in our case set to 20 in dim=1\n",
        "* ntokens = len(vocab), total number of different tokens in the data\n",
        "* len(text) = total number of tokens of the whole text\n",
        "* nhid = number of values in hidden layer\n",
        "* emsize = embedding size\n",
        "\n",
        "### Step by step\n",
        "\n",
        "1. in **corpus** only the index of every word is kept, so every word goes from dimension *ntokens* to a scalar value:   \n",
        "      dim token: [ntokens] -> [1]\n",
        "\n",
        "2. after **batchify(training_data)** , dividing the total text by the batch size and having *batch_size* many sequences:  \n",
        "      dim: [len(text)] -> [len(text) / bsz, bsz]\n",
        "\n",
        "3. after **get_batch(data, i)** get on sequence of size bptt for every batch:   \n",
        "    dim data: [len(text) / bsz,  bsz] -> [bptt, bsz]  \n",
        "    dim target: [len(text)] -> [bptt * bsz]\n",
        "    \n",
        "4. In the Net  \n",
        "    1. Input dim: [bptt, bsz]\n",
        "    2. hidden layer dim: (ht-1, ht): ([1, bsz, nhid], [1, bsz, nhid])\n",
        "    3. embedding layer dim: [bptt, bsz, emsize]\n",
        "    4. lstm layer dim: [bptt, bsz, emsize], hidden layer"
      ]
    },
    {
      "metadata": {
        "id": "GlUcox7uezsf",
        "colab_type": "code",
        "outputId": "7f39f541-15e6-4d60-daa1-0317437fa74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2822
        }
      },
      "cell_type": "code",
      "source": [
        "# [method_name for method_name in dir(nn.RNN)\n",
        "#  if callable(getattr(nn.RNN, method_name))]\n",
        "\n",
        "for i in rnn_pt.named_parameters():\n",
        "  print(i[0], i[1])\n",
        "\n",
        "print(rnn_pt.forward)\n",
        "\n",
        "for el in dir(rnn_pt):\n",
        "  print(el)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weight_ih_l0 Parameter containing:\n",
            "tensor([[ 0.0570,  0.0325,  0.0189,  ...,  0.0003,  0.0020, -0.0051],\n",
            "        [-0.0652, -0.0458, -0.0119,  ...,  0.0604,  0.0518, -0.0349],\n",
            "        [ 0.0103, -0.0330,  0.0539,  ..., -0.0286, -0.0249, -0.0535],\n",
            "        ...,\n",
            "        [-0.0342,  0.0368, -0.0072,  ..., -0.0362, -0.0624, -0.0534],\n",
            "        [-0.0208, -0.0699, -0.0090,  ...,  0.0071, -0.0498,  0.0638],\n",
            "        [ 0.0366,  0.0317,  0.0204,  ..., -0.0263,  0.0156,  0.0087]],\n",
            "       requires_grad=True)\n",
            "weight_hh_l0 Parameter containing:\n",
            "tensor([[-0.0653,  0.0089, -0.0366,  ...,  0.0704, -0.0615,  0.0476],\n",
            "        [-0.0279, -0.0296, -0.0317,  ...,  0.0018, -0.0658,  0.0076],\n",
            "        [ 0.0561,  0.0579,  0.0167,  ..., -0.0332, -0.0495, -0.0416],\n",
            "        ...,\n",
            "        [ 0.0557, -0.0258, -0.0673,  ..., -0.0306,  0.0201, -0.0108],\n",
            "        [-0.0630, -0.0141,  0.0312,  ..., -0.0008,  0.0000, -0.0391],\n",
            "        [-0.0467,  0.0008,  0.0345,  ...,  0.0381, -0.0057, -0.0267]],\n",
            "       requires_grad=True)\n",
            "bias_ih_l0 Parameter containing:\n",
            "tensor([-0.0227, -0.0487,  0.0562,  0.0198, -0.0615, -0.0522,  0.0049, -0.0695,\n",
            "         0.0690,  0.0192,  0.0393,  0.0623, -0.0100, -0.0035, -0.0142, -0.0126,\n",
            "         0.0231, -0.0358, -0.0436, -0.0085,  0.0573,  0.0351,  0.0512, -0.0406,\n",
            "         0.0476, -0.0505, -0.0650, -0.0263, -0.0489, -0.0629, -0.0478,  0.0160,\n",
            "        -0.0130, -0.0526,  0.0697,  0.0622,  0.0307, -0.0568,  0.0146,  0.0217,\n",
            "         0.0550,  0.0002,  0.0087,  0.0621, -0.0016,  0.0108,  0.0379, -0.0502,\n",
            "         0.0462,  0.0373, -0.0059, -0.0276,  0.0412, -0.0124, -0.0521, -0.0508,\n",
            "        -0.0562,  0.0412,  0.0095, -0.0505,  0.0573,  0.0543,  0.0618,  0.0007,\n",
            "        -0.0469, -0.0336, -0.0191,  0.0171, -0.0160, -0.0218,  0.0661, -0.0570,\n",
            "         0.0077, -0.0409,  0.0040,  0.0658, -0.0494, -0.0379,  0.0041,  0.0540,\n",
            "        -0.0637, -0.0451, -0.0157, -0.0165, -0.0642,  0.0689,  0.0177,  0.0700,\n",
            "        -0.0463, -0.0620,  0.0590,  0.0051, -0.0497, -0.0560, -0.0009,  0.0584,\n",
            "        -0.0140,  0.0703, -0.0153,  0.0103,  0.0537,  0.0589, -0.0483,  0.0025,\n",
            "        -0.0224,  0.0398,  0.0303, -0.0630, -0.0450,  0.0180, -0.0554,  0.0005,\n",
            "        -0.0594,  0.0124, -0.0529, -0.0234,  0.0279, -0.0561, -0.0590, -0.0257,\n",
            "        -0.0151,  0.0342,  0.0118, -0.0650, -0.0264,  0.0107,  0.0428, -0.0393,\n",
            "         0.0379, -0.0109, -0.0427, -0.0182,  0.0527, -0.0311,  0.0661,  0.0150,\n",
            "        -0.0395,  0.0395,  0.0404,  0.0634,  0.0670,  0.0098, -0.0583, -0.0448,\n",
            "        -0.0236, -0.0240,  0.0103,  0.0375, -0.0043, -0.0539, -0.0503,  0.0440,\n",
            "         0.0123, -0.0047,  0.0621,  0.0087, -0.0215, -0.0286,  0.0360, -0.0431,\n",
            "        -0.0611,  0.0432,  0.0121, -0.0638, -0.0435, -0.0585,  0.0421, -0.0384,\n",
            "        -0.0228, -0.0425, -0.0177,  0.0238, -0.0322, -0.0289, -0.0700, -0.0388,\n",
            "        -0.0218,  0.0314, -0.0270, -0.0641, -0.0511,  0.0199,  0.0442,  0.0545,\n",
            "        -0.0549, -0.0160, -0.0362, -0.0105, -0.0250, -0.0570,  0.0162, -0.0301,\n",
            "        -0.0596,  0.0148,  0.0082, -0.0031, -0.0143, -0.0014, -0.0018,  0.0512],\n",
            "       requires_grad=True)\n",
            "bias_hh_l0 Parameter containing:\n",
            "tensor([ 0.0595,  0.0206, -0.0601, -0.0317, -0.0477, -0.0218,  0.0585, -0.0202,\n",
            "        -0.0247, -0.0612,  0.0374,  0.0155,  0.0016, -0.0448, -0.0253, -0.0316,\n",
            "        -0.0493,  0.0312, -0.0085, -0.0081, -0.0458,  0.0114, -0.0695,  0.0550,\n",
            "        -0.0248,  0.0332,  0.0162, -0.0250,  0.0223, -0.0363,  0.0304,  0.0111,\n",
            "         0.0093,  0.0254,  0.0664, -0.0555,  0.0644,  0.0474, -0.0655, -0.0115,\n",
            "        -0.0243, -0.0549, -0.0467, -0.0021, -0.0353, -0.0248,  0.0509,  0.0453,\n",
            "         0.0388,  0.0200,  0.0653, -0.0252, -0.0288,  0.0699, -0.0022,  0.0101,\n",
            "        -0.0575, -0.0476, -0.0611, -0.0230, -0.0336,  0.0494,  0.0475, -0.0575,\n",
            "        -0.0059, -0.0432, -0.0668, -0.0120,  0.0266,  0.0372, -0.0272, -0.0599,\n",
            "        -0.0571,  0.0446,  0.0430,  0.0655, -0.0133, -0.0602, -0.0608,  0.0686,\n",
            "         0.0588, -0.0316, -0.0318, -0.0225, -0.0062, -0.0097, -0.0373,  0.0191,\n",
            "        -0.0517,  0.0651, -0.0540, -0.0127,  0.0129,  0.0558,  0.0228, -0.0440,\n",
            "         0.0037, -0.0462, -0.0471,  0.0098,  0.0142, -0.0592,  0.0393, -0.0116,\n",
            "        -0.0015, -0.0249, -0.0390, -0.0169,  0.0058,  0.0070,  0.0391,  0.0646,\n",
            "         0.0358,  0.0062,  0.0596,  0.0278, -0.0395, -0.0365,  0.0470,  0.0009,\n",
            "        -0.0564,  0.0080,  0.0514,  0.0222, -0.0374, -0.0300, -0.0387, -0.0660,\n",
            "         0.0127,  0.0623,  0.0310, -0.0600, -0.0309,  0.0208, -0.0182,  0.0651,\n",
            "        -0.0254, -0.0077, -0.0338,  0.0627, -0.0594,  0.0154,  0.0390,  0.0104,\n",
            "        -0.0151,  0.0104, -0.0127, -0.0065,  0.0092,  0.0057,  0.0650, -0.0301,\n",
            "        -0.0510, -0.0431,  0.0190,  0.0137, -0.0693,  0.0411,  0.0037, -0.0612,\n",
            "         0.0116,  0.0220, -0.0088,  0.0051, -0.0096,  0.0036, -0.0629, -0.0075,\n",
            "        -0.0078, -0.0611,  0.0042,  0.0254,  0.0352,  0.0153,  0.0109, -0.0195,\n",
            "         0.0593, -0.0309,  0.0075, -0.0701, -0.0341, -0.0375, -0.0322,  0.0306,\n",
            "         0.0615,  0.0304, -0.0074,  0.0037, -0.0408, -0.0475, -0.0596,  0.0381,\n",
            "         0.0705, -0.0343,  0.0059,  0.0462,  0.0383,  0.0129,  0.0690, -0.0559],\n",
            "       requires_grad=True)\n",
            "<bound method RNNBase.forward of RNN(200, 200)>\n",
            "__call__\n",
            "__class__\n",
            "__delattr__\n",
            "__dict__\n",
            "__dir__\n",
            "__doc__\n",
            "__eq__\n",
            "__format__\n",
            "__ge__\n",
            "__getattr__\n",
            "__getattribute__\n",
            "__gt__\n",
            "__hash__\n",
            "__init__\n",
            "__init_subclass__\n",
            "__le__\n",
            "__lt__\n",
            "__module__\n",
            "__ne__\n",
            "__new__\n",
            "__reduce__\n",
            "__reduce_ex__\n",
            "__repr__\n",
            "__setattr__\n",
            "__setstate__\n",
            "__sizeof__\n",
            "__str__\n",
            "__subclasshook__\n",
            "__weakref__\n",
            "_all_buffers\n",
            "_all_weights\n",
            "_apply\n",
            "_backend\n",
            "_backward_hooks\n",
            "_buffers\n",
            "_data_ptrs\n",
            "_forward_hooks\n",
            "_forward_pre_hooks\n",
            "_get_name\n",
            "_load_from_state_dict\n",
            "_modules\n",
            "_parameters\n",
            "_slow_forward\n",
            "_tracing_name\n",
            "_version\n",
            "add_module\n",
            "all_weights\n",
            "apply\n",
            "batch_first\n",
            "bias\n",
            "bias_hh_l0\n",
            "bias_ih_l0\n",
            "bidirectional\n",
            "check_forward_args\n",
            "children\n",
            "cpu\n",
            "cuda\n",
            "double\n",
            "dropout\n",
            "dropout_state\n",
            "dump_patches\n",
            "eval\n",
            "extra_repr\n",
            "flatten_parameters\n",
            "float\n",
            "forward\n",
            "half\n",
            "hidden_size\n",
            "input_size\n",
            "load_state_dict\n",
            "mode\n",
            "modules\n",
            "named_children\n",
            "named_modules\n",
            "named_parameters\n",
            "num_layers\n",
            "parameters\n",
            "register_backward_hook\n",
            "register_buffer\n",
            "register_forward_hook\n",
            "register_forward_pre_hook\n",
            "register_parameter\n",
            "reset_parameters\n",
            "share_memory\n",
            "state_dict\n",
            "to\n",
            "train\n",
            "training\n",
            "type\n",
            "weight_hh_l0\n",
            "weight_ih_l0\n",
            "zero_grad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sjGgZkehwnMk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}